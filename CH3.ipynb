{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sutton \n",
    " \n",
    "## Chapter 3 - The Reinforcement Learning Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridworld\n",
    "\n",
    "Calculate $P^{\\pi}(v)$ using dynamic programming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search solution.\n",
      "3.5     8.7     4.4     5.2     1.2     \n",
      "1.4     3.3     2.6     1.9     0.6     \n",
      "0.2     0.8     0.7     0.4     -0.6    \n",
      "-0.9    -0.4    -0.3    -0.7    -1.2    \n",
      "-2.0    -1.3    -1.4    -1.6    -1.8    \n",
      "DP solution.\n",
      "3.3     8.8     4.4     5.3     1.5     \n",
      "1.5     3.0     2.3     1.9     0.5     \n",
      "0.1     0.7     0.7     0.4     -0.4    \n",
      "-1.0    -0.4    -0.4    -0.6    -1.2    \n",
      "-1.9    -1.3    -1.2    -1.4    -2.0    \n"
     ]
    }
   ],
   "source": [
    "class Grid:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\" Setup new game board. \"\"\"\n",
    "        self.grid = {}\n",
    "        self.width = 5\n",
    "        self.height = 5\n",
    "        self.gamma = 0.9\n",
    "        \n",
    "        # setup grid\n",
    "        for x in range(1,self.width+1):\n",
    "            for y in range(1,self.height+1):\n",
    "                if (x, y) == (2,1):\n",
    "                    self.grid[(x,y)] = (10, 2, 5)\n",
    "                elif (x, y) == (4,1):\n",
    "                    self.grid[(x,y)] = (5, 4, 3)\n",
    "                else:\n",
    "                    self.grid[(x,y)] = (0, 0, 0)\n",
    "              \n",
    "    def get_new_position(self, x, y, dx, dy):\n",
    "        \"\"\" Returns (reward, x, y) after a move from (x,y) in the direction (dx, dy) \"\"\"\n",
    "\n",
    "        (reward, teleportX, teleportY) = self.grid[(x, y)]\n",
    "        \n",
    "        if (teleportX != 0):\n",
    "            return (reward, teleportX, teleportY)\n",
    "        else:\n",
    "            if (x + dx, y + dy) in self.grid:\n",
    "                return (0, x + dx, y + dy)\n",
    "            else:\n",
    "                return (-1, x, y)    \n",
    "    \n",
    "\n",
    "def solve_dp(grid):\n",
    "    \"\"\" Finds expected value at each square under random movement policy \n",
    "        using dynamic programming. \"\"\"\n",
    "\n",
    "    moves = [(-1,0),(+1,0),(0,-1),(0,+1)]\n",
    "\n",
    "    NUM_STEPS = 100\n",
    "    \n",
    "    result = {}\n",
    "    for x in range(1,grid.width+1):\n",
    "        for y in range(1,grid.height+1):\n",
    "            result[(x,y)] = 0.0\n",
    "            \n",
    "    # we solve the bellman equations using dp\n",
    "    for step in range(NUM_STEPS):\n",
    "        old_result = result.copy()\n",
    "        for x in range(1,grid.width+1):\n",
    "            for y in range(1,grid.height+1):\n",
    "                result[(x,y)] = 0.0\n",
    "                for (dx,dy) in moves:\n",
    "                    (reward, nx, ny) = grid.get_new_position(x, y, dx, dy)\n",
    "                    # bellman is pi(x,y) = (prob action occurs) * (reward for this state + discount * previous estimated pi(new state))\n",
    "                    # note: this feels a lot like finding a stable solution to a markov chain...\n",
    "                    result[(x,y)] += 0.25 * (reward + grid.gamma * old_result[(nx, ny)])\n",
    "            \n",
    "    return result\n",
    "    \n",
    "\n",
    "\n",
    "def solve_random_search(grid):\n",
    "    \"\"\" Finds expected value at each square via a randomised search. \"\"\"\n",
    "    \n",
    "    moves = [(-1,0),(+1,0),(0,-1),(0,+1)]\n",
    "    \n",
    "    NUM_TRIALS = 200\n",
    "    NUM_MOVES = 100\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for x in range(1,grid.width+1):\n",
    "        for y in range(1,grid.height+1):\n",
    "            total_score = 0\n",
    "            for i in range(NUM_TRIALS):\n",
    "                score = 0\n",
    "                atX = x\n",
    "                atY = y\n",
    "                for j in range(NUM_MOVES):\n",
    "                    dx, dy = moves[random.randint(0,3)]\n",
    "                    (reward, atX, atY) = grid.get_new_position(atX, atY, dx, dy)\n",
    "                    score += (grid.gamma ** j) * reward\n",
    "                total_score += score\n",
    "            result[(x,y)] = total_score / NUM_TRIALS \n",
    "    \n",
    "    return result\n",
    "            \n",
    "def print_result(result):\n",
    "    \n",
    "    for y in range(1,5+1):\n",
    "        s = \"\"\n",
    "        for x in range(1,5+1):\n",
    "            s += \"{0:.01f}\".format(result[(x,y)]).ljust(8)\n",
    "        print(s)\n",
    "        \n",
    "grid = Grid()\n",
    "\n",
    "result = solve_random_search(grid)\n",
    "print(\"Random search solution.\")\n",
    "print_result(result)\n",
    "\n",
    "result = solve_dp(grid)\n",
    "print(\"DP solution.\")\n",
    "print_result(result)\n",
    "\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
